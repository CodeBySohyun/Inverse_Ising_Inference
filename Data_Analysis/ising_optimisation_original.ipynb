{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Currency Ising Model Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for data manipulation, numerical processing, and optimisation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and Prepare Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the data matrix is: (4538, 26)\n"
     ]
    }
   ],
   "source": [
    "# Load the currency data from an csv file into a pandas DataFrame\n",
    "df = pd.read_csv(\"Results/data_matrix.csv\")\n",
    "\n",
    "# Extract column names from the DataFrame excluding any non-currency columns like 'Date'\n",
    "symbols = df.columns.tolist()[1:]\n",
    "\n",
    "# Remove the 'Date' column to focus solely on currency data and convert to a numpy matrix for analysis\n",
    "data_matrix = df.drop(columns=[\"Date\"]).to_numpy()\n",
    "\n",
    "# Output the shape of the matrix to ensure it has the expected dimensions\n",
    "print(f\"The shape of the data matrix is: {data_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Subset Optimisation (6/7/6/7):\n",
    "- Divide the full J matrix and h vector into 4 subsets according to the proposed configuration.\n",
    "- Optimise each subset multiple times to construct a symmetric J matrix and an h vector for all 26 currencies.\n",
    "- Display the initial guesses for J and h with appropriate significant figures for clarity. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and Extract Currency Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define indices for currency subsets to be used in separate optimisation analyses\n",
    "subsets_indices = {\n",
    "    'subset_1': list(range(6)),     # First subset (first 6 currencies)\n",
    "    'subset_2': list(range(6, 13)), # Second subset (next 7 currencies)\n",
    "    'subset_3': list(range(13, 19)), # Third subset (next 6 currencies)\n",
    "    'subset_4': list(range(19, 26))  # Fourth subset (last 7 currencies)\n",
    "}\n",
    "\n",
    "# Extract the data subsets for analysis based on the defined indices\n",
    "data_subsets = {key: data_matrix[:, indices] for key, indices in subsets_indices.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Log-Pseudo-Likelihood Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the log-pseudo-likelihood and its gradients for optimisation\n",
    "\n",
    "def log_pseudolikelihood_and_gradients(J, h, X):\n",
    "    \"\"\"\n",
    "    Calculate the log-pseudolikelihood for the Ising model and its gradients.\n",
    "    \n",
    "    Args:\n",
    "    J: Interaction matrix (J matrix).\n",
    "    h: External field vector (h vector).\n",
    "    X: Spin configurations (data matrix).\n",
    "    \n",
    "    Returns:\n",
    "    Tuple of negative log-pseudolikelihood, gradients of J, and gradients of h.\n",
    "    \"\"\"\n",
    "    n, d = X.shape  # Number of samples and dimensions\n",
    "    log_likelihood = 0\n",
    "    grad_J = np.zeros_like(J)  # Initialise the gradient of J\n",
    "    grad_h = np.zeros_like(h)  # Initialise the gradient of h\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(d):\n",
    "            S_ij = np.dot(J[j, :], X[i, :]) - J[j, j] * X[i, j] + h[j]\n",
    "            log_likelihood += X[i, j] * S_ij - np.log(2 * np.cosh(S_ij))\n",
    "            grad_h[j] += X[i, j] - np.tanh(S_ij)\n",
    "            for k in range(d):\n",
    "                if k != j:\n",
    "                    grad_J[j, k] += X[i, j] * X[i, k] - np.tanh(S_ij) * X[i, k]\n",
    "    \n",
    "    grad_J = (grad_J + grad_J.T) / 2  # Make the J gradient symmetric\n",
    "\n",
    "    # Return the negative likelihood and gradients for minimisation\n",
    "    return -log_likelihood, -grad_J, -grad_h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset Optimisation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimisation function using the L-BFGS-B algorithm\n",
    "\n",
    "def optimise_subset(data_subset, J_subset, h_subset):\n",
    "    \"\"\"\n",
    "    Optimise a subset of the Ising model using the L-BFGS-B algorithm.\n",
    "    \n",
    "    Args:\n",
    "    data_subset: Subset of data for optimisation.\n",
    "    J_subset: Initial guess for the interaction matrix (J matrix) for the subset.\n",
    "    h_subset: Initial guess for the external field vector (h vector) for the subset.\n",
    "    \n",
    "    Returns:\n",
    "    Optimised interaction matrix (J matrix), external field vector (h vector), and a success flag.\n",
    "    \"\"\"\n",
    "    N = J_subset.shape[0]  # Number of spins (currencies)\n",
    "\n",
    "    # Flatten the J matrix and h vector for the optimisation\n",
    "    x0 = np.concatenate([J_subset[np.triu_indices(N, k=1)], h_subset])\n",
    "\n",
    "    def objective_function(x):\n",
    "        # Construct the symmetric J matrix and calculate the likelihood and gradients\n",
    "        J, h = reconstruct_J_and_h(x, N)\n",
    "        likelihood, grad_J, grad_h = log_pseudolikelihood_and_gradients(J, h, data_subset)\n",
    "        # Combine and return the likelihood and flattened gradients\n",
    "        return likelihood, np.concatenate([grad_J[np.triu_indices(N, k=1)], grad_h])\n",
    "    \n",
    "    # Execute the optimisation using the objective function and initial guesses\n",
    "    res = minimize(objective_function, x0, method='L-BFGS-B', jac=True)\n",
    "\n",
    "    # Reconstruct the optimised J matrix and h vector from the optimisation result\n",
    "    J_optimised, h_optimised = reconstruct_J_and_h(res.x, N)\n",
    "\n",
    "    return J_optimised, h_optimised, res.success\n",
    "\n",
    "# Helper function to reconstruct the symmetric J matrix and h vector from a flattened array\n",
    "def reconstruct_J_and_h(flattened_array, N):\n",
    "    # Extract the upper triangular part of J and the h vector from the flattened array\n",
    "    J_upper_tri = flattened_array[:N * (N - 1) // 2]\n",
    "    h = flattened_array[N * (N - 1) // 2:]\n",
    "\n",
    "    # Construct the symmetric J matrix from the upper triangular part\n",
    "    J = np.zeros((N, N))\n",
    "    J[np.triu_indices(N, k=1)] = J_upper_tri\n",
    "    J += J.T  # Symmetrise the J matrix\n",
    "    np.fill_diagonal(J, 0)  # Set the diagonal to 0 as there are no self-interactions\n",
    "\n",
    "    return J, h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Initialise and Optimise First Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimised J matrix for subset 1:\n",
      " [[ 0.          0.15363498  0.1863861   0.01296148  0.53258729  0.30021676]\n",
      " [ 0.15363498  0.          0.34385924  0.17001976  0.15934126  0.11217307]\n",
      " [ 0.1863861   0.34385924  0.          0.08919781  0.0852463   0.15266204]\n",
      " [ 0.01296148  0.17001976  0.08919781  0.          0.07359777 -0.07208994]\n",
      " [ 0.53258729  0.15934126  0.0852463   0.07359777  0.          0.17436713]\n",
      " [ 0.30021676  0.11217307  0.15266204 -0.07208994  0.17436713  0.        ]]\n",
      "Optimised h vector for subset 1:\n",
      " [ 0.04166438  0.00674824 -0.02915886 -0.03756775  0.01753722 -0.01687403]\n",
      "Optimisation successful for subset 1:\n",
      " True\n"
     ]
    }
   ],
   "source": [
    "# Initialise the J matrix and h vector for the first subset for optimisation\n",
    "J_initial_subset_1 = np.zeros((6, 6))  # 6x6 matrix for the first 6 currencies\n",
    "h_initial_subset_1 = np.zeros(6)       # Vector of length 6 for the external field\n",
    "\n",
    "# Optimise the first subset using the initialised J matrix and h vector\n",
    "J_subset_optimised_1, h_subset_optimised_1, optimisation_success_1 = optimise_subset(\n",
    "    data_subsets['subset_1'], J_initial_subset_1, h_initial_subset_1)\n",
    "\n",
    "# Display the optimised J matrix, h vector, and whether the optimisation was successful\n",
    "print(\"Optimised J matrix for subset 1:\\n\", J_subset_optimised_1)\n",
    "print(\"Optimised h vector for subset 1:\\n\", h_subset_optimised_1)\n",
    "print(\"Optimisation successful for subset 1:\\n\", optimisation_success_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Optimisation of Currency Subsets (6/7/6/7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimised J matrices for each subset:\n",
      " {'subset_1': array([[ 0.        ,  0.15363498,  0.1863861 ,  0.01296148,  0.53258729,\n",
      "         0.30021676],\n",
      "       [ 0.15363498,  0.        ,  0.34385924,  0.17001976,  0.15934126,\n",
      "         0.11217307],\n",
      "       [ 0.1863861 ,  0.34385924,  0.        ,  0.08919781,  0.0852463 ,\n",
      "         0.15266204],\n",
      "       [ 0.01296148,  0.17001976,  0.08919781,  0.        ,  0.07359777,\n",
      "        -0.07208994],\n",
      "       [ 0.53258729,  0.15934126,  0.0852463 ,  0.07359777,  0.        ,\n",
      "         0.17436713],\n",
      "       [ 0.30021676,  0.11217307,  0.15266204, -0.07208994,  0.17436713,\n",
      "         0.        ]]), 'subset_2': array([[0.        , 0.03150901, 0.12884488, 0.49855793, 0.03136831,\n",
      "        0.10086422, 0.04214823],\n",
      "       [0.03150901, 0.        , 0.03867503, 0.05117874, 0.06978797,\n",
      "        0.03110047, 0.11163803],\n",
      "       [0.12884488, 0.03867503, 0.        , 0.61624577, 0.00190711,\n",
      "        0.38373779, 0.0135196 ],\n",
      "       [0.49855793, 0.05117874, 0.61624577, 0.        , 0.01132158,\n",
      "        0.37239007, 0.09834097],\n",
      "       [0.03136831, 0.06978797, 0.00190711, 0.01132158, 0.        ,\n",
      "        0.0550609 , 0.03538913],\n",
      "       [0.10086422, 0.03110047, 0.38373779, 0.37239007, 0.0550609 ,\n",
      "        0.        , 0.10349897],\n",
      "       [0.04214823, 0.11163803, 0.0135196 , 0.09834097, 0.03538913,\n",
      "        0.10349897, 0.        ]]), 'subset_3': array([[0.        , 0.09587908, 0.10489293, 0.00290499, 0.06676278,\n",
      "        0.20240439],\n",
      "       [0.09587908, 0.        , 0.19375957, 0.0522468 , 0.02161618,\n",
      "        0.12537178],\n",
      "       [0.10489293, 0.19375957, 0.        , 0.05461632, 0.10961968,\n",
      "        0.20437421],\n",
      "       [0.00290499, 0.0522468 , 0.05461632, 0.        , 0.12746711,\n",
      "        0.11578465],\n",
      "       [0.06676278, 0.02161618, 0.10961968, 0.12746711, 0.        ,\n",
      "        0.08579538],\n",
      "       [0.20240439, 0.12537178, 0.20437421, 0.11578465, 0.08579538,\n",
      "        0.        ]]), 'subset_4': array([[0.        , 0.07509664, 0.00702624, 0.14711597, 0.09685605,\n",
      "        0.05392522, 0.03607041],\n",
      "       [0.07509664, 0.        , 0.17703168, 0.07090083, 0.02482762,\n",
      "        0.12423488, 0.16766669],\n",
      "       [0.00702624, 0.17703168, 0.        , 0.35071457, 0.10141522,\n",
      "        0.10647852, 0.12347967],\n",
      "       [0.14711597, 0.07090083, 0.35071457, 0.        , 0.21359875,\n",
      "        0.10282967, 0.25347763],\n",
      "       [0.09685605, 0.02482762, 0.10141522, 0.21359875, 0.        ,\n",
      "        0.02685047, 0.08471498],\n",
      "       [0.05392522, 0.12423488, 0.10647852, 0.10282967, 0.02685047,\n",
      "        0.        , 0.29524313],\n",
      "       [0.03607041, 0.16766669, 0.12347967, 0.25347763, 0.08471498,\n",
      "        0.29524313, 0.        ]])}\n",
      "Optimised h vectors for each subset:\n",
      " {'subset_1': array([ 0.04166438,  0.00674824, -0.02915886, -0.03756775,  0.01753722,\n",
      "       -0.01687403]), 'subset_2': array([-0.02150061,  0.04796208,  0.01943636, -0.0061221 , -0.04420099,\n",
      "        0.0157844 , -0.04064068]), 'subset_3': array([ 0.0426813 ,  0.00235272, -0.00159684,  0.03589678, -0.0417007 ,\n",
      "       -0.00719509]), 'subset_4': array([ 0.00942943, -0.00291374, -0.00141839,  0.01145004, -0.01322096,\n",
      "       -0.06819928,  0.03940445])}\n",
      "Optimisation success status for each subset:\n",
      " {'subset_1': True, 'subset_2': True, 'subset_3': True, 'subset_4': True}\n"
     ]
    }
   ],
   "source": [
    "# Initialise storage for optimised J matrices, h vectors, and success indicators for each subset\n",
    "optimised_J_subsets = {}\n",
    "optimised_h_subsets = {}\n",
    "optimisation_success_subsets = {}\n",
    "\n",
    "# Iterate over each subset and carry out the optimisation process\n",
    "for subset_name, data_subset in data_subsets.items():\n",
    "    # Find out the number of currencies in the current subset\n",
    "    subset_size = len(subsets_indices[subset_name])\n",
    "    \n",
    "    # Set up initial guesses for the J matrix and h vector for the optimisation\n",
    "    J_initial = np.zeros((subset_size, subset_size))  # Initialise a square matrix of zeros for J\n",
    "    h_initial = np.zeros(subset_size)                 # Initialise a zero vector for h\n",
    "    \n",
    "    # Conduct the optimisation using the initial guesses and the current data subset\n",
    "    J_optimised, h_optimised, optimisation_success = optimise_subset(\n",
    "        data_subset,\n",
    "        J_initial,\n",
    "        h_initial\n",
    "    )\n",
    "    \n",
    "    # If the optimisation is successful, store the resulting J and h in their respective dictionaries\n",
    "    if optimisation_success:\n",
    "        optimised_J_subsets[subset_name] = J_optimised\n",
    "        optimised_h_subsets[subset_name] = h_optimised\n",
    "    # Record the success status of the optimisation for each subset\n",
    "    optimisation_success_subsets[subset_name] = optimisation_success\n",
    "\n",
    "# Display the optimised J matrices, h vectors, and success status for each subset\n",
    "print(\"Optimised J matrices for each subset:\\n\", optimised_J_subsets)\n",
    "print(\"Optimised h vectors for each subset:\\n\", optimised_h_subsets)\n",
    "print(\"Optimisation success status for each subset:\\n\", optimisation_success_subsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Larger Subset Optimisation (13/13):\n",
    "- Use the updated  J  matrix and  h  vector from the converged subsets as initial guesses to optimise two larger subsets, each consisting of 13 currencies.\n",
    "- Optimise these larger subsets until convergence. Each subset optimisation updates the J matrix and h vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix and Vector Aggregation for Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to combine smaller matrices and vectors into larger, unified structures for optimisation analysis.\n",
    "\n",
    "def combine_J_matrices(*matrices):\n",
    "    \"\"\"\n",
    "    Combine smaller J matrices into a larger J matrix.\n",
    "    Args:\n",
    "    *matrices: An unpacked tuple of smaller J matrices.\n",
    "    \n",
    "    Returns:\n",
    "    A combined larger J matrix.\n",
    "    \"\"\"\n",
    "    # Calculate the total size for the new combined matrix\n",
    "    size = sum(m.shape[0] for m in matrices)\n",
    "    # Initialise the combined matrix with zeros\n",
    "    J_combined = np.zeros((size, size))\n",
    "\n",
    "    current_index = 0  # Starting index for combining matrices\n",
    "    for m in matrices:\n",
    "        m_size = m.shape[0]  # Size of the current matrix\n",
    "        # Insert the current matrix into the combined matrix at the correct position\n",
    "        J_combined[current_index:current_index+m_size, current_index:current_index+m_size] = m\n",
    "        current_index += m_size  # Update the index for the next matrix\n",
    "\n",
    "    return J_combined\n",
    "\n",
    "def combine_h_vectors(*vectors):\n",
    "    \"\"\"\n",
    "    Combine smaller h vectors into a larger h vector.\n",
    "    Args:\n",
    "    *vectors: An unpacked tuple of smaller h vectors.\n",
    "    \n",
    "    Returns:\n",
    "    A combined larger h vector.\n",
    "    \"\"\"\n",
    "    # Concatenate all vectors into a single, longer vector\n",
    "    return np.concatenate(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Matrices and Vectors for Larger Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined J matrix for the first 13x13 subset:\n",
      " [[ 0.          0.15363498  0.1863861   0.01296148  0.53258729  0.30021676\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.15363498  0.          0.34385924  0.17001976  0.15934126  0.11217307\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.1863861   0.34385924  0.          0.08919781  0.0852463   0.15266204\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.01296148  0.17001976  0.08919781  0.          0.07359777 -0.07208994\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.53258729  0.15934126  0.0852463   0.07359777  0.          0.17436713\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.30021676  0.11217307  0.15266204 -0.07208994  0.17436713  0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.03150901  0.12884488  0.49855793  0.03136831  0.10086422\n",
      "   0.04214823]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.03150901  0.          0.03867503  0.05117874  0.06978797  0.03110047\n",
      "   0.11163803]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.12884488  0.03867503  0.          0.61624577  0.00190711  0.38373779\n",
      "   0.0135196 ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.49855793  0.05117874  0.61624577  0.          0.01132158  0.37239007\n",
      "   0.09834097]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.03136831  0.06978797  0.00190711  0.01132158  0.          0.0550609\n",
      "   0.03538913]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.10086422  0.03110047  0.38373779  0.37239007  0.0550609   0.\n",
      "   0.10349897]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.04214823  0.11163803  0.0135196   0.09834097  0.03538913  0.10349897\n",
      "   0.        ]]\n",
      "Combined h vector for the first 13x13 subset:\n",
      " [ 0.04166438  0.00674824 -0.02915886 -0.03756775  0.01753722 -0.01687403\n",
      " -0.02150061  0.04796208  0.01943636 -0.0061221  -0.04420099  0.0157844\n",
      " -0.04064068]\n",
      "Combined J matrix for the second 13x13 subset:\n",
      " [[0.         0.09587908 0.10489293 0.00290499 0.06676278 0.20240439\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.09587908 0.         0.19375957 0.0522468  0.02161618 0.12537178\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.10489293 0.19375957 0.         0.05461632 0.10961968 0.20437421\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.00290499 0.0522468  0.05461632 0.         0.12746711 0.11578465\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.06676278 0.02161618 0.10961968 0.12746711 0.         0.08579538\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.20240439 0.12537178 0.20437421 0.11578465 0.08579538 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.07509664 0.00702624 0.14711597 0.09685605 0.05392522\n",
      "  0.03607041]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.07509664 0.         0.17703168 0.07090083 0.02482762 0.12423488\n",
      "  0.16766669]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.00702624 0.17703168 0.         0.35071457 0.10141522 0.10647852\n",
      "  0.12347967]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.14711597 0.07090083 0.35071457 0.         0.21359875 0.10282967\n",
      "  0.25347763]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.09685605 0.02482762 0.10141522 0.21359875 0.         0.02685047\n",
      "  0.08471498]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.05392522 0.12423488 0.10647852 0.10282967 0.02685047 0.\n",
      "  0.29524313]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.03607041 0.16766669 0.12347967 0.25347763 0.08471498 0.29524313\n",
      "  0.        ]]\n",
      "Combined h vector for the second 13x13 subset:\n",
      " [ 0.0426813   0.00235272 -0.00159684  0.03589678 -0.0417007  -0.00719509\n",
      "  0.00942943 -0.00291374 -0.00141839  0.01145004 -0.01322096 -0.06819928\n",
      "  0.03940445]\n"
     ]
    }
   ],
   "source": [
    "# Combine matrices and vectors from previously optimised smaller subsets to form two larger 13x13 subsets for further optimisation.\n",
    "\n",
    "# Combine the first two J matrices and h vectors to form the first larger subset\n",
    "J_13x13_1 = combine_J_matrices(optimised_J_subsets['subset_1'], optimised_J_subsets['subset_2'])\n",
    "h_13x13_1 = combine_h_vectors(optimised_h_subsets['subset_1'], optimised_h_subsets['subset_2'])\n",
    "\n",
    "# Combine the last two J matrices and h vectors to form the second larger subset\n",
    "J_13x13_2 = combine_J_matrices(optimised_J_subsets['subset_3'], optimised_J_subsets['subset_4'])\n",
    "h_13x13_2 = combine_h_vectors(optimised_h_subsets['subset_3'], optimised_h_subsets['subset_4'])\n",
    "\n",
    "# Print the combined matrices and vectors to verify their construction\n",
    "print(\"Combined J matrix for the first 13x13 subset:\\n\", J_13x13_1)\n",
    "print(\"Combined h vector for the first 13x13 subset:\\n\", h_13x13_1)\n",
    "print(\"Combined J matrix for the second 13x13 subset:\\n\", J_13x13_2)\n",
    "print(\"Combined h vector for the second 13x13 subset:\\n\", h_13x13_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation of the First 13x13 Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimisation results for the first 13x13 subset:\n",
      " [[ 0.00000000e+00 -2.48091800e-02  1.57922812e-01  1.46600482e-02\n",
      "   5.14589760e-01  2.71787486e-01 -1.39514014e-02  5.02724203e-02\n",
      "   6.17500778e-02  6.96137276e-02  6.86732621e-02  1.49963080e-01\n",
      "   1.13545507e-01]\n",
      " [-2.48091800e-02  0.00000000e+00  1.04496133e-01  9.10396175e-04\n",
      "   1.18569886e-01 -5.85771413e-02  2.19469508e-01  4.37163033e-03\n",
      "   3.51774337e-01  1.34394761e+00  8.16329758e-02  1.27915100e-01\n",
      "   2.88826511e-02]\n",
      " [ 1.57922812e-01  1.04496133e-01  0.00000000e+00  6.55660896e-02\n",
      "   7.14245787e-02  1.29924894e-01  9.90097063e-02  1.49091416e-02\n",
      "   1.14654575e-01  8.86081884e-02  3.00446680e-02  9.03856006e-02\n",
      "   1.70646328e-02]\n",
      " [ 1.46600482e-02  9.10396175e-04  6.55660896e-02  0.00000000e+00\n",
      "   6.55205322e-02 -7.87198621e-02  2.92417911e-01  1.24078851e-02\n",
      "   1.22733039e-02  5.76902975e-02  1.46680481e-02 -6.54215693e-02\n",
      "  -1.01380459e-02]\n",
      " [ 5.14589760e-01  1.18569886e-01  7.14245787e-02  6.55205322e-02\n",
      "   0.00000000e+00  1.62615362e-01  3.41395342e-02  5.73527598e-02\n",
      "   4.95537771e-02 -2.93926002e-02  3.99559599e-02  3.52473694e-02\n",
      "   2.99066903e-02]\n",
      " [ 2.71787486e-01 -5.85771413e-02  1.29924894e-01 -7.87198621e-02\n",
      "   1.62615362e-01  0.00000000e+00  2.15031553e-02  2.94838398e-02\n",
      "   7.94734147e-02  7.16926573e-02  2.50005426e-02  9.05230225e-02\n",
      "   5.08672092e-02]\n",
      " [-1.39514014e-02  2.19469508e-01  9.90097063e-02  2.92417911e-01\n",
      "   3.41395342e-02  2.15031553e-02  0.00000000e+00  1.97480400e-02\n",
      "   8.48877275e-02  2.74148850e-01  1.46514202e-02  9.24032517e-02\n",
      "   3.40565145e-02]\n",
      " [ 5.02724203e-02  4.37163033e-03  1.49091416e-02  1.24078851e-02\n",
      "   5.73527598e-02  2.94838398e-02  1.97480400e-02  0.00000000e+00\n",
      "   1.86418275e-02  3.09204182e-02  5.89462050e-02  7.58790593e-03\n",
      "   9.74371794e-02]\n",
      " [ 6.17500778e-02  3.51774337e-01  1.14654575e-01  1.22733039e-02\n",
      "   4.95537771e-02  7.94734147e-02  8.48877275e-02  1.86418275e-02\n",
      "   0.00000000e+00  2.78150529e-01 -2.48262257e-02  3.25903776e-01\n",
      "  -1.50287851e-02]\n",
      " [ 6.96137276e-02  1.34394761e+00  8.86081884e-02  5.76902975e-02\n",
      "  -2.93926002e-02  7.16926573e-02  2.74148850e-01  3.09204182e-02\n",
      "   2.78150529e-01  0.00000000e+00 -7.72350423e-02  2.26783084e-01\n",
      "   5.10223154e-02]\n",
      " [ 6.86732621e-02  8.16329758e-02  3.00446680e-02  1.46680481e-02\n",
      "   3.99559599e-02  2.50005426e-02  1.46514202e-02  5.89462050e-02\n",
      "  -2.48262257e-02 -7.72350423e-02  0.00000000e+00  2.75786997e-02\n",
      "   1.98482908e-02]\n",
      " [ 1.49963080e-01  1.27915100e-01  9.03856006e-02 -6.54215693e-02\n",
      "   3.52473694e-02  9.05230225e-02  9.24032517e-02  7.58790593e-03\n",
      "   3.25903776e-01  2.26783084e-01  2.75786997e-02  0.00000000e+00\n",
      "   6.62181467e-02]\n",
      " [ 1.13545507e-01  2.88826511e-02  1.70646328e-02 -1.01380459e-02\n",
      "   2.99066903e-02  5.08672092e-02  3.40565145e-02  9.74371794e-02\n",
      "  -1.50287851e-02  5.10223154e-02  1.98482908e-02  6.62181467e-02\n",
      "   0.00000000e+00]] [ 0.04730169  0.00905936 -0.02884179 -0.03534476  0.01852761 -0.0157697\n",
      " -0.00899551  0.04566751  0.01676696 -0.00991345 -0.04657011  0.00799462\n",
      " -0.04532694]\n",
      "Optimisation successful: True\n"
     ]
    }
   ],
   "source": [
    "# Perform optimisation on the first 13x13 subset using the combined J matrix and h vector as initial guesses.\n",
    "\n",
    "# Extract the combined data of the first two subsets for optimisation\n",
    "data_13x13_1 = np.hstack((data_subsets['subset_1'], data_subsets['subset_2']))\n",
    "\n",
    "# Optimise the first 13x13 subset using a predefined function `optimise_subset`\n",
    "J_13x13_optimised_1, h_13x13_optimised_1, optimisation_success_13x13_1 = optimise_subset(\n",
    "    data_13x13_1,\n",
    "    J_13x13_1,\n",
    "    h_13x13_1\n",
    ")\n",
    "\n",
    "# Display the optimised J matrix, h vector, and success status for the first larger subset\n",
    "print(\"Optimisation results for the first 13x13 subset:\\n\", J_13x13_optimised_1, h_13x13_optimised_1)\n",
    "print(\"Optimisation successful:\", optimisation_success_13x13_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation of the Second 13x13 Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimisation results for the second 13x13 subset:\n",
      " [[ 0.          0.04882446  0.04840694 -0.01910868  0.04359987  0.08597943\n",
      "   0.04810597  0.04952335  0.09290486  0.07760196  0.01296876  0.10823934\n",
      "   0.04748053]\n",
      " [ 0.04882446  0.          0.10754786  0.02013554 -0.01322754  0.01537513\n",
      "   0.13649823  0.11247997  0.01211739  0.08300673  0.07553298  0.05443731\n",
      "   0.09986477]\n",
      " [ 0.04840694  0.10754786  0.          0.01441151  0.05749356  0.05901221\n",
      "   0.13003002  0.06121611  0.01653348  0.19273527  0.17710194  0.04990353\n",
      "   0.07435432]\n",
      " [-0.01910868  0.02013554  0.01441151  0.          0.11455467  0.05104383\n",
      "   0.00086878  0.00950599  0.00314511  0.04759558  0.03825156 -0.00106092\n",
      "   0.15913524]\n",
      " [ 0.04359987 -0.01322754  0.05749356  0.11455467  0.          0.02646624\n",
      "   0.05021963  0.04649796  0.00224389  0.12054005  0.06061223  0.01639867\n",
      "  -0.00538839]\n",
      " [ 0.08597943  0.01537513  0.05901221  0.05104383  0.02646624  0.\n",
      "   0.02321516  0.11516793  0.53733089  0.15822078  0.08496776  0.0094716\n",
      "   0.17989052]\n",
      " [ 0.04810597  0.13649823  0.13003002  0.00086878  0.05021963  0.02321516\n",
      "   0.          0.04268904 -0.02084576  0.09227817  0.05600758  0.03222354\n",
      "   0.00349211]\n",
      " [ 0.04952335  0.11247997  0.06121611  0.00950599  0.04649796  0.11516793\n",
      "   0.04268904  0.          0.11169193  0.01976668 -0.00873688  0.10614736\n",
      "   0.1292356 ]\n",
      " [ 0.09290486  0.01211739  0.01653348  0.00314511  0.00224389  0.53733089\n",
      "  -0.02084576  0.11169193  0.          0.25247736  0.04879239  0.08491962\n",
      "   0.02475584]\n",
      " [ 0.07760196  0.08300673  0.19273527  0.04759558  0.12054005  0.15822078\n",
      "   0.09227817  0.01976668  0.25247736  0.          0.14742006  0.07357464\n",
      "   0.18929978]\n",
      " [ 0.01296876  0.07553298  0.17710194  0.03825156  0.06061223  0.08496776\n",
      "   0.05600758 -0.00873688  0.04879239  0.14742006  0.          0.00872998\n",
      "   0.04147471]\n",
      " [ 0.10823934  0.05443731  0.04990353 -0.00106092  0.01639867  0.0094716\n",
      "   0.03222354  0.10614736  0.08491962  0.07357464  0.00872998  0.\n",
      "   0.27724269]\n",
      " [ 0.04748053  0.09986477  0.07435432  0.15913524 -0.00538839  0.17989052\n",
      "   0.00349211  0.1292356   0.02475584  0.18929978  0.04147471  0.27724269\n",
      "   0.        ]] [ 0.04944083  0.00535577  0.00191883  0.034751   -0.04041642 -0.00364519\n",
      "  0.0074781  -0.00559302 -0.00671655  0.00810568 -0.01460181 -0.07275562\n",
      "  0.02950463]\n",
      "Optimisation successful: True\n"
     ]
    }
   ],
   "source": [
    "# Perform optimisation on the second 13x13 subset, following the same process as for the first subset.\n",
    "\n",
    "# Combine the data for the third and fourth subsets for optimisation\n",
    "data_13x13_2 = np.hstack((data_subsets['subset_3'], data_subsets['subset_4']))\n",
    "\n",
    "# Optimise the second 13x13 subset using the same `optimise_subset` function\n",
    "J_13x13_optimised_2, h_13x13_optimised_2, optimisation_success_13x13_2 = optimise_subset(\n",
    "    data_13x13_2,\n",
    "    J_13x13_2,\n",
    "    h_13x13_2\n",
    ")\n",
    "\n",
    "# Display the optimised J matrix, h vector, and success status for the second larger subset\n",
    "print(\"Optimisation results for the second 13x13 subset:\\n\", J_13x13_optimised_2, h_13x13_optimised_2)\n",
    "print(\"Optimisation successful:\", optimisation_success_13x13_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Full Matrix Optimisation:\n",
    "- Finally, use the converged  J  matrix and  h  vector from the 13/13 subsets as initial guesses for the optimisation of the full matrix.\n",
    "- Run the full-matrix optimisation until convergence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Optimised Subsets and Perform Full Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimisation of the full matrix was successful.\n",
      "Optimised full J matrix:\n",
      " [[ 0.00000000e+00 -5.36594612e-02  1.14766267e-01  1.80898935e-02\n",
      "   4.33767632e-01  2.04047524e-01 -4.96570304e-02  1.23368243e-02\n",
      "   1.98088918e-02  2.72257756e-02  5.25456781e-02  7.70118928e-02\n",
      "   6.24121512e-02 -9.31380938e-03 -3.66641756e-03  5.25847087e-02\n",
      "   3.51880106e-03  2.88184428e-02  5.83618696e-02 -6.21224589e-03\n",
      "   8.66078698e-02  8.62189971e-02  1.99489803e-01  2.54765794e-02\n",
      "   4.45908182e-02  1.59310082e-01]\n",
      " [-5.36594612e-02  0.00000000e+00  9.53623706e-02  1.20807511e-02\n",
      "   1.04051971e-01 -7.83026061e-02  1.97863460e-01 -7.07258263e-03\n",
      "   3.37568921e-01  1.33642369e+00  7.86237097e-02  1.04659247e-01\n",
      "   1.13893591e-02  3.04232999e-02 -5.81539622e-02  8.25985302e-02\n",
      "  -2.34875978e-02  2.74707712e-02 -2.56296979e-02 -4.69738895e-02\n",
      "   7.10323476e-02  1.24382355e-01 -5.12651718e-02  8.45791125e-02\n",
      "   4.35568491e-02  1.98234452e-02]\n",
      " [ 1.14766267e-01  9.53623706e-02  0.00000000e+00  6.68083970e-02\n",
      "   2.92414473e-02  9.36672595e-02  7.49888362e-02 -7.79310288e-03\n",
      "   9.08609019e-02  5.70996739e-02  2.29161437e-02  6.34857552e-02\n",
      "  -6.17908733e-03  2.26725407e-02  1.77642811e-02  1.43191879e-02\n",
      "   4.66580897e-02  1.61356752e-02  1.09898145e-01  7.14977308e-04\n",
      "   1.58326966e-02  3.08722911e-02  9.30188199e-02  2.68278177e-02\n",
      "  -1.97364959e-02  1.20711253e-02]\n",
      " [ 1.80898935e-02  1.20807511e-02  6.68083970e-02  0.00000000e+00\n",
      "   6.85089086e-02 -6.30917536e-02  2.92583403e-01  1.21802886e-02\n",
      "   1.94955234e-02  6.42185404e-02  1.63989338e-02 -4.43067834e-02\n",
      "  -5.90471790e-03 -3.76490250e-02 -3.33764955e-03 -9.66493990e-03\n",
      "  -4.35730920e-02  1.84530595e-03 -4.43377024e-02 -2.93431437e-02\n",
      "  -4.98001811e-02 -3.19684653e-02  1.14596166e-01  5.16905865e-02\n",
      "  -7.40713977e-02 -1.87392968e-02]\n",
      " [ 4.33767632e-01  1.04051971e-01  2.92414473e-02  6.85089086e-02\n",
      "   0.00000000e+00  1.04682981e-01  3.82832086e-03  2.12151559e-02\n",
      "   1.17784519e-02 -6.91169419e-02  2.42732483e-02 -2.25712875e-02\n",
      "  -1.67282432e-02  2.27250831e-02  3.43763944e-02  6.26130179e-02\n",
      "   6.51917969e-02 -1.01049813e-02  1.13389188e-01  2.33913642e-02\n",
      "  -2.69521678e-02  5.63184461e-02  1.59048665e-01  1.62485010e-02\n",
      "   2.88375958e-02  8.69971993e-02]\n",
      " [ 2.04047524e-01 -7.83026061e-02  9.36672595e-02 -6.30917536e-02\n",
      "   1.04682981e-01  0.00000000e+00 -6.29952273e-03  2.25449116e-03\n",
      "   4.71689041e-02  3.32414712e-02  1.52661341e-02  3.88193487e-02\n",
      "   2.00242366e-02  4.43068514e-02 -8.77386159e-03  1.79361897e-02\n",
      "   6.44851084e-02 -3.21631045e-02  1.57988699e-01  1.95081773e-02\n",
      "   7.98662325e-02  2.10641250e-02  7.06454489e-02  3.66129906e-02\n",
      "   2.76983812e-02  8.55745948e-02]\n",
      " [-4.96570304e-02  1.97863460e-01  7.49888362e-02  2.92583403e-01\n",
      "   3.82832086e-03 -6.29952273e-03  0.00000000e+00  4.39769095e-03\n",
      "   6.28354707e-02  2.32220956e-01  1.01593268e-02  6.51793654e-02\n",
      "   2.79025000e-02  3.88975651e-02 -2.29103262e-02 -6.82943685e-03\n",
      "  -3.10385354e-02  2.16871267e-02  1.18100160e-01 -2.83728852e-02\n",
      "   3.15682518e-03  1.04456846e-01  8.54398598e-02  2.51161360e-02\n",
      "   9.72136778e-03 -4.12821849e-02]\n",
      " [ 1.23368243e-02 -7.07258263e-03 -7.79310288e-03  1.21802886e-02\n",
      "   2.12151559e-02  2.25449116e-03  4.39769095e-03  0.00000000e+00\n",
      "  -3.70522530e-04  1.45436997e-02  4.51452804e-02 -1.44956137e-02\n",
      "   6.29501561e-02  3.70893563e-02  3.32548222e-02  5.51794602e-02\n",
      "   1.79288262e-02  1.75850636e-02  5.54072524e-02  6.09274207e-02\n",
      "   1.77929521e-02  6.95279648e-03  8.08227010e-02  4.76403496e-02\n",
      "  -1.08457472e-02 -1.87879016e-02]\n",
      " [ 1.98088918e-02  3.37568921e-01  9.08609019e-02  1.94955234e-02\n",
      "   1.17784519e-02  4.71689041e-02  6.28354707e-02 -3.70522530e-04\n",
      "   0.00000000e+00  2.46908827e-01 -3.37295942e-02  2.92458441e-01\n",
      "  -3.37591586e-02  7.09403320e-02  1.94304649e-02 -6.12370099e-04\n",
      "   5.60419389e-02 -1.81163911e-03  2.91959945e-02  8.74747531e-03\n",
      "   1.91533692e-02  9.90349270e-02  7.48587544e-02  6.21166883e-04\n",
      "   4.75288879e-03  2.14458749e-02]\n",
      " [ 2.72257756e-02  1.33642369e+00  5.70996739e-02  6.42185404e-02\n",
      "  -6.91169419e-02  3.32414712e-02  2.32220956e-01  1.45436997e-02\n",
      "   2.46908827e-01  0.00000000e+00 -8.37020002e-02  1.96705170e-01\n",
      "   4.86962532e-02 -2.59669244e-03  3.49301313e-03 -9.34801409e-02\n",
      "  -6.56536489e-03  1.54995912e-02  1.35820727e-01  5.53296373e-02\n",
      "   2.31129344e-02  1.99142511e-01  1.03906003e-01 -4.78935978e-02\n",
      "  -4.92670486e-02 -3.72663193e-02]\n",
      " [ 5.25456781e-02  7.86237097e-02  2.29161437e-02  1.63989338e-02\n",
      "   2.42732483e-02  1.52661341e-02  1.01593268e-02  4.51452804e-02\n",
      "  -3.37295942e-02 -8.37020002e-02  0.00000000e+00  1.36261806e-02\n",
      "  -1.73241135e-03  3.45860383e-02  3.52158504e-02  4.65740819e-02\n",
      "  -1.94451047e-02  5.85356873e-03 -1.13468933e-02  4.96568561e-02\n",
      "   8.26066850e-03  1.57525927e-02  2.50448366e-02  6.44634741e-03\n",
      "   1.59794453e-03  3.18999446e-04]\n",
      " [ 7.70118928e-02  1.04659247e-01  6.34857552e-02 -4.43067834e-02\n",
      "  -2.25712875e-02  3.88193487e-02  6.51793654e-02 -1.44956137e-02\n",
      "   2.92458441e-01  1.96705170e-01  1.36261806e-02  0.00000000e+00\n",
      "   2.96977189e-02  6.89809839e-02  7.05279077e-02 -1.58988930e-02\n",
      "  -2.08257182e-02 -9.12887062e-03  6.33857920e-02  1.79140753e-02\n",
      "   7.66005579e-03  1.00743333e-01  4.35319144e-02  2.68749289e-02\n",
      "   1.39716448e-01  1.21954039e-01]\n",
      " [ 6.24121512e-02  1.13893591e-02 -6.17908733e-03 -5.90471790e-03\n",
      "  -1.67282432e-02  2.00242366e-02  2.79025000e-02  6.29501561e-02\n",
      "  -3.37591586e-02  4.86962532e-02 -1.73241135e-03  2.96977189e-02\n",
      "   0.00000000e+00 -9.14905777e-03  9.40000118e-02  1.09911032e-01\n",
      "   2.18843407e-02  5.51450909e-02  3.45323643e-04  9.59241216e-02\n",
      "   1.81899291e-02  1.55996082e-02  5.05441217e-02  4.57063714e-02\n",
      "   2.16817063e-02  3.21789145e-02]\n",
      " [-9.31380938e-03  3.04232999e-02  2.26725407e-02 -3.76490250e-02\n",
      "   2.27250831e-02  4.43068514e-02  3.88975651e-02  3.70893563e-02\n",
      "   7.09403320e-02 -2.59669244e-03  3.45860383e-02  6.89809839e-02\n",
      "  -9.14905777e-03  0.00000000e+00  4.20686599e-02  4.22414823e-02\n",
      "  -2.62237401e-02  3.99943665e-02  4.34492474e-02  4.11370664e-02\n",
      "   3.42660298e-02  2.86839161e-02  4.10994455e-02  1.34908728e-03\n",
      "   9.33985487e-02  2.93389709e-02]\n",
      " [-3.66641756e-03 -5.81539622e-02  1.77642811e-02 -3.33764955e-03\n",
      "   3.43763944e-02 -8.77386159e-03 -2.29103262e-02  3.32548222e-02\n",
      "   1.94304649e-02  3.49301313e-03  3.52158504e-02  7.05279077e-02\n",
      "   9.40000118e-02  4.20686599e-02  0.00000000e+00  9.13757471e-02\n",
      "   1.41539958e-02 -1.82450534e-02  6.93810356e-03  1.21591725e-01\n",
      "   1.08886686e-01  6.21699314e-03  6.44827967e-02  6.80820023e-02\n",
      "   4.48082078e-02  8.46821438e-02]\n",
      " [ 5.25847087e-02  8.25985302e-02  1.43191879e-02 -9.66493990e-03\n",
      "   6.26130179e-02  1.79361897e-02 -6.82943685e-03  5.51794602e-02\n",
      "  -6.12370099e-04 -9.34801409e-02  4.65740819e-02 -1.58988930e-02\n",
      "   1.09911032e-01  4.22414823e-02  9.13757471e-02  0.00000000e+00\n",
      "   3.74009644e-03  4.96172979e-02  3.93387177e-02  1.11573910e-01\n",
      "   5.04095385e-02  5.79002646e-03  1.54609932e-01  1.63996964e-01\n",
      "   4.25964462e-02  5.04612921e-02]\n",
      " [ 3.51880106e-03 -2.34875978e-02  4.66580897e-02 -4.35730920e-02\n",
      "   6.51917969e-02  6.44851084e-02 -3.10385354e-02  1.79288262e-02\n",
      "   5.60419389e-02 -6.56536489e-03 -1.94451047e-02 -2.08257182e-02\n",
      "   2.18843407e-02 -2.62237401e-02  1.41539958e-02  3.74009644e-03\n",
      "   0.00000000e+00  1.15009055e-01  2.84892137e-02 -6.15414316e-03\n",
      "  -3.34358219e-04 -2.03945103e-03  2.41811587e-02  3.40015693e-02\n",
      "  -8.18260178e-03  1.38730810e-01]\n",
      " [ 2.88184428e-02  2.74707712e-02  1.61356752e-02  1.84530595e-03\n",
      "  -1.01049813e-02 -3.21631045e-02  2.16871267e-02  1.75850636e-02\n",
      "  -1.81163911e-03  1.54995912e-02  5.85356873e-03 -9.12887062e-03\n",
      "   5.51450909e-02  3.99943665e-02 -1.82450534e-02  4.96172979e-02\n",
      "   1.15009055e-01  0.00000000e+00  1.70716700e-02  4.47317304e-02\n",
      "   4.21950550e-02 -2.16143270e-02  1.02478609e-01  5.36994733e-02\n",
      "   1.55184305e-02 -6.60245096e-03]\n",
      " [ 5.83618696e-02 -2.56296979e-02  1.09898145e-01 -4.43377024e-02\n",
      "   1.13389188e-01  1.57988699e-01  1.18100160e-01  5.54072524e-02\n",
      "   2.91959945e-02  1.35820727e-01 -1.13468933e-02  6.33857920e-02\n",
      "   3.45323643e-04  4.34492474e-02  6.93810356e-03  3.93387177e-02\n",
      "   2.84892137e-02  1.70716700e-02  0.00000000e+00  1.29970313e-02\n",
      "   7.22294464e-02  4.02334897e-01  2.60723431e-02  5.16908888e-02\n",
      "  -1.96668846e-02  1.21315867e-01]\n",
      " [-6.21224589e-03 -4.69738895e-02  7.14977308e-04 -2.93431437e-02\n",
      "   2.33913642e-02  1.95081773e-02 -2.83728852e-02  6.09274207e-02\n",
      "   8.74747531e-03  5.53296373e-02  4.96568561e-02  1.79140753e-02\n",
      "   9.59241216e-02  4.11370664e-02  1.21591725e-01  1.11573910e-01\n",
      "  -6.15414316e-03  4.47317304e-02  1.29970313e-02  0.00000000e+00\n",
      "   3.50278773e-02 -3.13269388e-02  7.55027067e-02  4.83820505e-02\n",
      "   2.54465075e-02 -8.43882027e-03]\n",
      " [ 8.66078698e-02  7.10323476e-02  1.58326966e-02 -4.98001811e-02\n",
      "  -2.69521678e-02  7.98662325e-02  3.15682518e-03  1.77929521e-02\n",
      "   1.91533692e-02  2.31129344e-02  8.26066850e-03  7.66005579e-03\n",
      "   1.81899291e-02  3.42660298e-02  1.08886686e-01  5.04095385e-02\n",
      "  -3.34358219e-04  4.21950550e-02  7.22294464e-02  3.50278773e-02\n",
      "   0.00000000e+00  5.86643621e-02 -2.27567475e-02 -1.99295372e-02\n",
      "   9.25732163e-02  1.02698221e-01]\n",
      " [ 8.62189971e-02  1.24382355e-01  3.08722911e-02 -3.19684653e-02\n",
      "   5.63184461e-02  2.10641250e-02  1.04456846e-01  6.95279648e-03\n",
      "   9.90349270e-02  1.99142511e-01  1.57525927e-02  1.00743333e-01\n",
      "   1.55996082e-02  2.86839161e-02  6.21699314e-03  5.79002646e-03\n",
      "  -2.03945103e-03 -2.16143270e-02  4.02334897e-01 -3.13269388e-02\n",
      "   5.86643621e-02  0.00000000e+00  1.09671099e-01  5.65780958e-03\n",
      "   4.96814356e-02 -2.61960351e-02]\n",
      " [ 1.99489803e-01 -5.12651718e-02  9.30188199e-02  1.14596166e-01\n",
      "   1.59048665e-01  7.06454489e-02  8.54398598e-02  8.08227010e-02\n",
      "   7.48587544e-02  1.03906003e-01  2.50448366e-02  4.35319144e-02\n",
      "   5.05441217e-02  4.10994455e-02  6.44827967e-02  1.54609932e-01\n",
      "   2.41811587e-02  1.02478609e-01  2.60723431e-02  7.55027067e-02\n",
      "  -2.27567475e-02  1.09671099e-01  0.00000000e+00  1.02103189e-01\n",
      "   4.94523102e-02  1.08097088e-01]\n",
      " [ 2.54765794e-02  8.45791125e-02  2.68278177e-02  5.16905865e-02\n",
      "   1.62485010e-02  3.66129906e-02  2.51161360e-02  4.76403496e-02\n",
      "   6.21166883e-04 -4.78935978e-02  6.44634741e-03  2.68749289e-02\n",
      "   4.57063714e-02  1.34908728e-03  6.80820023e-02  1.63996964e-01\n",
      "   3.40015693e-02  5.36994733e-02  5.16908888e-02  4.83820505e-02\n",
      "  -1.99295372e-02  5.65780958e-03  1.02103189e-01  0.00000000e+00\n",
      "   3.23510485e-03  2.50896726e-02]\n",
      " [ 4.45908182e-02  4.35568491e-02 -1.97364959e-02 -7.40713977e-02\n",
      "   2.88375958e-02  2.76983812e-02  9.72136778e-03 -1.08457472e-02\n",
      "   4.75288879e-03 -4.92670486e-02  1.59794453e-03  1.39716448e-01\n",
      "   2.16817063e-02  9.33985487e-02  4.48082078e-02  4.25964462e-02\n",
      "  -8.18260178e-03  1.55184305e-02 -1.96668846e-02  2.54465075e-02\n",
      "   9.25732163e-02  4.96814356e-02  4.94523102e-02  3.23510485e-03\n",
      "   0.00000000e+00  2.46869507e-01]\n",
      " [ 1.59310082e-01  1.98234452e-02  1.20711253e-02 -1.87392968e-02\n",
      "   8.69971993e-02  8.55745948e-02 -4.12821849e-02 -1.87879016e-02\n",
      "   2.14458749e-02 -3.72663193e-02  3.18999446e-04  1.21954039e-01\n",
      "   3.21789145e-02  2.93389709e-02  8.46821438e-02  5.04612921e-02\n",
      "   1.38730810e-01 -6.60245096e-03  1.21315867e-01 -8.43882027e-03\n",
      "   1.02698221e-01 -2.61960351e-02  1.08097088e-01  2.50896726e-02\n",
      "   2.46869507e-01  0.00000000e+00]]\n",
      "Optimised full h vector:\n",
      " [ 0.0498724   0.01225203 -0.03177924 -0.03684714  0.01441473 -0.02010848\n",
      " -0.00665547  0.04379171  0.01352467 -0.00215015 -0.04766519  0.01027778\n",
      " -0.04446619  0.04772985  0.0074668   0.00298782  0.03207468 -0.03879879\n",
      " -0.00793568  0.00902998 -0.00875478 -0.00946421  0.00914648 -0.01254371\n",
      " -0.07823494  0.02319528]\n"
     ]
    }
   ],
   "source": [
    "# Combine the optimised 13x13 J matrices into a single 26x26 J matrix for the full optimisation\n",
    "J_initial_full = np.block([\n",
    "    [J_13x13_optimised_1, np.zeros((13, 13))],  # Top-left block is the first optimised J matrix\n",
    "    [np.zeros((13, 13)), J_13x13_optimised_2]   # Bottom-right block is the second optimised J matrix\n",
    "])\n",
    "\n",
    "# Combine the optimised h vectors into a single 26-dimensional h vector\n",
    "h_initial_full = np.concatenate([h_13x13_optimised_1, h_13x13_optimised_2])\n",
    "\n",
    "# Conduct the final optimisation for the entire set of currencies\n",
    "J_optimised_full, h_optimised_full, success = optimise_subset(\n",
    "    data_matrix,  # The full data matrix containing all currency pairs\n",
    "    J_initial_full,\n",
    "    h_initial_full\n",
    ")\n",
    "\n",
    "# Confirm the outcome of the full matrix optimisation\n",
    "if success:\n",
    "    print(\"Optimisation of the full matrix was successful.\")\n",
    "else:\n",
    "    print(\"Optimisation of the full matrix did not converge.\")\n",
    "\n",
    "# Display the optimised full J matrix and h vector\n",
    "print(\"Optimised full J matrix:\\n\", J_optimised_full)\n",
    "print(\"Optimised full h vector:\\n\", h_optimised_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to DataFrames and Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimised J matrix has been saved to 'Results/J_matrix.csv'.\n",
      "The optimised h vector has been saved to 'Results/h_vector.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Convert the optimised J matrix and h vector into pandas DataFrames for easy manipulation and storage\n",
    "J_df = pd.DataFrame(J_optimised_full, columns=symbols, index=symbols)\n",
    "h_df = pd.DataFrame({'Symbol': symbols, 'h': h_optimised_full})\n",
    "\n",
    "# Define the file paths for saving the csv files\n",
    "J_matrix_file_path = 'Results/J_matrix.csv'\n",
    "h_vector_file_path = 'Results/h_vector.csv'\n",
    "\n",
    "# Save the J matrix and h vector to csv files for further analysis and record-keeping\n",
    "J_df.to_csv(J_matrix_file_path, index=False)\n",
    "h_df.to_csv(h_vector_file_path, index=False, header=False)\n",
    "\n",
    "# Confirm that the files have been saved\n",
    "print(f\"The optimised J matrix has been saved to '{J_matrix_file_path}'.\")\n",
    "print(f\"The optimised h vector has been saved to '{h_vector_file_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data matrix is: (4538, 26)\n",
      "Shape of optimised J matrix: (26, 26)\n",
      "Length of optimised h vector: 26\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of data matrix is: {data_matrix.shape}\")\n",
    "print(f\"Shape of optimised J matrix: {J_optimised_full.shape}\")\n",
    "print(f\"Length of optimised h vector: {len(h_optimised_full)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
